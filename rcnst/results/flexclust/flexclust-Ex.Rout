
R Under development (unstable) (2017-08-14 r73093) -- "Unsuffered Consequences"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "flexclust"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('flexclust')
Loading required package: grid
Loading required package: lattice
Loading required package: modeltools
Loading required package: stats4
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("Nclus")
> ### * Nclus
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Nclus
> ### Title: Artificial Example with 4 Gaussians
> ### Aliases: Nclus
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(Nclus)
> cl <- cclust(Nclus, k=4, simple=FALSE, save.data=TRUE)
> plot(cl)
> 
> 
> 
> cleanEx()
> nameEx("auto")
> ### * auto
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: auto
> ### Title: Automobile Customer Survey Data
> ### Aliases: auto
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(auto)
> summary(auto)
 model          gear      leasing             usage      previous_model
 A:312   4 gears  :181   Mode :logical   private :293   BMW 3   :202   
 B:294   5 econo  :527   FALSE:678       both    :456   BMW 5   :193   
 C:117   5 sport  : 31   TRUE :115       business: 44   BMW 7   :160   
 D: 70   automatic: 54                                  Mercedes: 45   
                                                        Opel    : 42   
                                                        VW      : 40   
                                                        (Other) :111   
     other_consider test_drive       info_adv        info_exp      
 same manuf :166    Mode :logical   Mode :logical   Mode :logical  
 other manuf:225    FALSE:503       FALSE:46        FALSE:425      
 both       : 95    TRUE :290       TRUE :747       TRUE :368      
 none       :307                                                   
                                                                   
                                                                   
                                                                   
  info_rec       ch_clarity      ch_economy      ch_driving_properties
 Mode :logical   Mode :logical   Mode :logical   Mode :logical        
 FALSE:469       FALSE:644       FALSE:570       FALSE:246            
 TRUE :324       TRUE :149       TRUE :223       TRUE :547            
                                                                      
                                                                      
                                                                      
                                                                      
 ch_service      ch_interior     ch_quality      ch_technology  
 Mode :logical   Mode :logical   Mode :logical   Mode :logical  
 FALSE:625       FALSE:598       FALSE:432       FALSE:445      
 TRUE :168       TRUE :195       TRUE :361       TRUE :348      
                                                                
                                                                
                                                                
                                                                
 ch_model_continuity ch_comfort      ch_reliability  ch_handling    
 Mode :logical       Mode :logical   Mode :logical   Mode :logical  
 FALSE:633           FALSE:485       FALSE:468       FALSE:562      
 TRUE :160           TRUE :308       TRUE :325       TRUE :231      
                                                                    
                                                                    
                                                                    
                                                                    
 ch_reputation   ch_concept      ch_character     ch_power      
 Mode :logical   Mode :logical   Mode :logical   Mode :logical  
 FALSE:643       FALSE:630       FALSE:696       FALSE:405      
 TRUE :150       TRUE :163       TRUE :97        TRUE :388      
                                                                
                                                                
                                                                
                                                                
 ch_resale_value ch_styling      ch_safety       ch_sporty      
 Mode :logical   Mode :logical   Mode :logical   Mode :logical  
 FALSE:604       FALSE:591       FALSE:476       FALSE:470      
 TRUE :189       TRUE :202       TRUE :317       TRUE :323      
                                                                
                                                                
                                                                
                                                                
 ch_consumption   ch_space        satisfaction        good1         good2    
 Mode :logical   Mode :logical   Min.   : 1.000   bad    : 90   bad    :146  
 FALSE:590       FALSE:683       1st Qu.: 2.000   neutral:469   neutral:534  
 TRUE :203       TRUE :110       Median : 3.000   good   :234   good   :113  
                                 Mean   : 2.719                              
                                 3rd Qu.: 3.000                              
                                 Max.   :10.000                              
                                                                             
     good3         good4         good5         good6         good7    
 bad    : 69   bad    : 88   bad    : 50   bad    : 46   bad    :203  
 neutral:527   neutral:494   neutral:692   neutral:729   neutral:457  
 good   :197   good   :211   good   : 51   good   : 18   good   :133  
                                                                      
                                                                      
                                                                      
                                                                      
          sporty        drive_char      tempo       consumption     gender   
 good        :674   gentle   : 39   < 130  : 75   low     :134   male  :744  
 more sport  : 61   speedy   :416   130-150:341   ok      :475   female: 49  
 more comfort: 58   powerfull:277   150-180:319   high    :147               
                    extreme  : 61   > 180  : 58   too high: 37               
                                                                             
                                                                             
                                                                             
         occupation  household
 self-employed:247   1-2:324  
 freelance    :140   >=3:469  
 employee     :406            
                              
                              
                              
                              
> 
> 
> 
> cleanEx()
> nameEx("barplot-methods")
> ### * barplot-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: barplot-methods
> ### Title: Barplot/chart Methods in Package 'flexclust'
> ### Aliases: barplot,kcca-method barplot,kccasimple-method
> ###   barchart,kcca-method barchart,kccasimple-method
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
>   cl <- cclust(iris[,-5], k=3)
>   barplot(cl)
>   barplot(cl, bycluster=FALSE)
> 
>   ## plot the maximum instead of mean value per cluster:
>   barplot(cl, bycluster=FALSE, data=iris[,-5],
+           FUN=function(x) apply(x,2,max))
> 
>   ## use lattice for plotting:
>   barchart(cl)
>   ## automatic abbreviation of labels
>   barchart(cl, scales=list(abbreviate=TRUE))
>   ## origin of bars at zero
>   barchart(cl, scales=list(abbreviate=TRUE), origin=0)
> 
>   ## Use manual labels. Note that the flexclust barchart orders bars
>   ## from top to bottom (the default does it the other way round), hence
>   ## we have to rev() the labels:
>   LAB <- c("SL", "SW", "PL", "PW")
>   barchart(cl, scales=list(y=list(labels=rev(LAB))), origin=0)
> 
>   ## deviation of each cluster center from the population means
>   barchart(cl, origin=rev(cl@xcent), mlcol=NULL)
> 
>   ## use shading to highlight large deviations from population mean
>   barchart(cl, shade=TRUE)
> 
>   ## use smaller deviation limit than default and add a legend
>   barchart(cl, shade=TRUE, diff=0.2, legend=TRUE)
NULL
> 
> 
> 
> cleanEx()
> nameEx("bootFlexclust")
> ### * bootFlexclust
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootFlexclust
> ### Title: Bootstrap Flexclust Algorithms
> ### Aliases: bootFlexclust bootFlexclust-class show,bootFlexclust-method
> ###   summary,bootFlexclust-method plot,bootFlexclust,missing-method
> ###   boxplot,bootFlexclust-method densityplot,bootFlexclust-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> ## Not run: 
> ##D 
> ##D ## data uniform on unit square
> ##D x <- matrix(runif(400), ncol=2)
> ##D 
> ##D cl <- FALSE
> ##D 
> ##D ## to run bootstrap replications on a workstation cluster do the following:
> ##D library("parallel")
> ##D cl <- makeCluster(2, type = "PSOCK")
> ##D clusterCall(cl, function() require("flexclust"))
> ##D 
> ##D 
> ##D ## 50 bootstrap replicates for speed in example,
> ##D ## use more for real applications
> ##D bcl <- bootFlexclust(x, k=2:7, nboot=50, FUN=cclust, multicore=cl)
> ##D 
> ##D bcl
> ##D summary(bcl)
> ##D 
> ##D ## splitting the square into four quadrants should be the most stable
> ##D ## solution (increase nboot if not)
> ##D plot(bcl)
> ##D densityplot(bcl, from=0)
> ## End(Not run)
> 
> 
> cleanEx()
> nameEx("bundestag")
> ### * bundestag
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bundestag
> ### Title: German Parliament Election Data
> ### Aliases: bundestag btw2002 btw2005 btw2009
> ### Keywords: datasets
> 
> ### ** Examples
> 
> p02 <- bundestag(2002)
> pairs(p02)
> p05 <- bundestag(2005)
> pairs(p05)
> p09 <- bundestag(2009)
> pairs(p09)
> 
> state <- bundestag(2002, state=TRUE)
> table(state)
state
    Baden-Wuerttemberg                 Bayern                 Berlin 
                    37                     45                     12 
           Brandenburg                 Bremen                Hamburg 
                    10                      2                      6 
                Hessen Mecklenburg-Vorpommern          Niedersachsen 
                    21                      7                     29 
   Nordrhein-Westfalen        Rheinland-Pfalz               Saarland 
                    64                     15                      4 
               Sachsen         Sachsen-Anhalt     Schleswig-Holstein 
                    17                     10                     11 
            Thueringen 
                     9 
> 
> start.with.b <- bundestag(2002, state="^B")
> table(start.with.b)
start.with.b
Baden-Wuerttemberg             Bayern             Berlin        Brandenburg 
                37                 45                 12                 10 
            Bremen              other 
                 2                193 
> 
> pairs(p09, col=2-(state=="Bayern"))
> 
> 
> 
> cleanEx()
> nameEx("bwplot-methods")
> ### * bwplot-methods
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bwplot-methods
> ### Title: Box-Whisker Plot Methods in Package 'flexclust'
> ### Aliases: bwplot,kcca-method bwplot,kccasimple-method
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
>   set.seed(1)
>   cl <- cclust(iris[,-5], k=3, save.data=TRUE)
>   bwplot(cl)
> 
>   ## fill only boxes with color which do not contain the overall median
>   ## (grey dot of background box)
>   bwplot(cl, shade=TRUE)
> 
>   ## fill only boxes with color which do not overlap with the box of the
>   ## complete sample (grey background box)
>   bwplot(cl, shadefun="boxOverlap")
> 
> 
> 
> cleanEx()
> nameEx("cclust")
> ### * cclust
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cclust
> ### Title: Convex Clustering
> ### Aliases: cclust
> ### Keywords: cluster
> 
> ### ** Examples
> 
> ## a 2-dimensional example
> x<-rbind(matrix(rnorm(100,sd=0.3),ncol=2),
+          matrix(rnorm(100,mean=1,sd=0.3),ncol=2))
> cl<-cclust(x,2)
> plot(x, col=predict(cl))
> points(cl@centers, pch="x", cex=2, col=3) 
> 
> ## a 3-dimensional example 
> x<-rbind(matrix(rnorm(150,sd=0.3),ncol=3),
+          matrix(rnorm(150,mean=2,sd=0.3),ncol=3),
+          matrix(rnorm(150,mean=4,sd=0.3),ncol=3))
> cl<-cclust(x, 6, method="neuralgas", save.data=TRUE)
> pairs(x, col=predict(cl))
> plot(cl)
> 
> 
> 
> cleanEx()
> nameEx("clusterSim")
> ### * clusterSim
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: clusterSim
> ### Title: Cluster Similarity Matrix
> ### Aliases: clusterSim clusterSim,kcca-method clusterSim,kccasimple-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> example(Nclus)

Nclus> data(Nclus)

Nclus> cl <- cclust(Nclus, k=4, simple=FALSE, save.data=TRUE)

Nclus> plot(cl)
> 
> clusterSim(cl)
          [,1]       [,2]      [,3]       [,4]
[1,] 1.0000000 0.19627858 0.1487398 0.01478760
[2,] 0.2886216 1.00000000 0.0000000 0.09947397
[3,] 0.3847919 0.01290624 1.0000000 0.00000000
[4,] 0.2042213 0.19280900 0.0000000 1.00000000
> clusterSim(cl, symmetric=TRUE)
          [,1]        [,2]        [,3]      [,4]
[1,] 1.0000000 0.242450084 0.266765871 0.1095044
[2,] 0.2424501 1.000000000 0.006453119 0.1461415
[3,] 0.2667659 0.006453119 1.000000000 0.0000000
[4,] 0.1095044 0.146141487 0.000000000 1.0000000
> 
> ## should have similar structure but will be numerically different:
> clusterSim(cl, symmetric=TRUE, data=Nclus[sample(1:550, 200),])
          [,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.2451655 0.2413617 0.1024861
[2,] 0.2451655 1.0000000 0.0000000 0.1337889
[3,] 0.2413617 0.0000000 1.0000000 0.0000000
[4,] 0.1024861 0.1337889 0.0000000 1.0000000
> 
> ## different concept of cluster similarity
> clusterSim(cl, method="centers")
          [,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.5268685 0.5178650 0.4523207
[2,] 0.5268685 1.0000000 0.3349004 0.4549684
[3,] 0.5178650 0.3349004 1.0000000 0.0000000
[4,] 0.4523207 0.4549684 0.0000000 1.0000000
> 
> 
> 
> cleanEx()
> nameEx("conversion")
> ### * conversion
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: conversion
> ### Title: Conversion Between S3 Partition Objects and KCCA
> ### Aliases: as.kcca as.kcca.hclust as.kcca.kmeans as.kcca.partition
> ###   as.kcca.skmeans coerce,kccasimple,kmeans-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> data(Nclus)
> 
> cl1 <- kmeans(Nclus, 4)
> cl1
K-means clustering with 4 clusters of sizes 99, 64, 89, 298

Cluster means:
       [,1]       [,2]
1  7.989868 0.04343217
2 -3.383112 5.86362845
3 -1.046518 6.00799046
4  2.726557 2.63263727

Clustering vector:
  [1] 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4
 [38] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4
 [75] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 3 4 1 1 1 1 1 1 1 1 1 1 1
[112] 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 2 3 2 2 2 3 3 3 2 2 2 2 2 3 3 2 3 3 3 2 3
[223] 3 2 2 3 3 2 3 3 3 3 2 4 3 3 2 3 3 3 3 2 2 3 2 3 3 3 2 3 2 2 2 2 3 3 2 2 3
[260] 2 3 2 3 3 3 4 2 2 2 3 2 2 3 2 2 3 3 3 2 2 3 3 2 2 3 3 3 3 3 3 3 2 2 3 3 3
[297] 3 3 3 2 3 3 3 3 3 2 3 2 2 3 3 2 3 2 2 3 3 3 3 3 2 3 2 2 3 3 3 2 3 3 3 3 3
[334] 3 2 2 3 2 2 3 2 2 2 2 3 2 3 2 3 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[371] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[408] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[445] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[482] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[519] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4

Within cluster sum of squares by cluster:
[1]  310.2337  148.2672  193.9469 2591.4567
 (between_SS / total_SS =  72.5 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss"
[6] "betweenss"    "size"         "iter"         "ifault"      
> cl1a <- as.kcca(cl1, Nclus)
> cl1a
kcca object of family ‘kmeans’ 

call:
as.kcca(object = cl1, data = Nclus)

cluster sizes:

  1   2   3   4 
 99  64  89 298 

> cl1b <- as(cl1a, "kmeans")
> 
> ## Don't show: 
> stopifnot(all.equal(cl1$cluster, clusters(cl1a)))
> stopifnot(all.equal(cl1$cluster, cl1b$cluster))
> stopifnot(all.equal(cl1$withinss, cl1b$withinss))
> ## End(Don't show)
> 
> library("cluster")
> cl2 <- pam(Nclus, 4)
> cl2
Medoids:
      ID                        
[1,]  63  0.08186574 -0.00820071
[2,] 443  4.00343823  3.97713041
[3,] 320 -1.99534740  6.08333766
[4,] 128  8.00570542 -0.22378175
Clustering vector:
  [1] 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4
[112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[149] 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
[186] 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3
[223] 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[260] 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[297] 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
[334] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2
[371] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[408] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[445] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[482] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[519] 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2
Objective function:
   build     swap 
1.490041 1.350180 

Available components:
 [1] "medoids"    "id.med"     "clustering" "objective"  "isolation" 
 [6] "clusinfo"   "silinfo"    "diss"       "call"       "data"      
> cl2a <- as.kcca(cl2)
> cl2a
kcca object of family ‘kmeans’ 

call:
as.kcca(object = cl2)

cluster sizes:

  1   2   3   4 
104 201 147  98 

> ## the same
> cl2b = as.kcca(cl2, Nclus)
> cl2b
kcca object of family ‘kmeans’ 

call:
as.kcca(object = cl2, data = Nclus)

cluster sizes:

  1   2   3   4 
104 201 147  98 

> 
> ## Don't show: 
> stopifnot(all.equal(clusters(cl2a), clusters(cl2b)))
> stopifnot(all.equal(parameters(cl2a), parameters(cl2b)))
> ## End(Don't show)
> 
> ## hierarchical clustering
> hc <- hclust(dist(USArrests))
> plot(hc)
> rect.hclust(hc, k=3)
> c3 <- cutree(hc, k=3)
> k3 <- as.kcca(hc, USArrests, k=3)
> barchart(k3)
> table(c3, clusters(k3))
   
c3   1  2  3
  1 16  0  0
  2  0 14  0
  3  0  0 20
> 
> 
> 
> cleanEx()

detaching ‘package:cluster’

> nameEx("dist2")
> ### * dist2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dist2
> ### Title: Compute pairwise distances between two data sets
> ### Aliases: dist2
> ### Keywords: multivariate cluster
> 
> ### ** Examples
> 
> x = matrix(rnorm(20), ncol=4)
> rownames(x) = paste("X", 1:nrow(x), sep=".")
> y = matrix(rnorm(12), ncol=4)
> rownames(y) = paste("Y", 1:nrow(y), sep=".")
> 
> dist2(x, y)
         Y.1      Y.2      Y.3
X.1 2.598021 3.863186 2.244731
X.2 2.676070 2.393283 1.033569
X.3 3.318443 1.877491 1.604838
X.4 3.382161 1.226973 2.565401
X.5 2.203277 2.895402 1.783920
> dist2(x, y, "man")
         Y.1      Y.2      Y.3
X.1 4.844766 7.235031 3.513144
X.2 4.191885 3.966355 1.607227
X.3 5.473622 3.000619 2.894362
X.4 5.703620 2.138595 4.813185
X.5 3.730119 4.738304 2.803972
> 
> data(milk)
> dist2(milk[1:5,], milk[4:6,])
            DONKEY    HIPPO    CAMEL
HORSE     1.225765 4.759464 4.107262
ORANGUTAN 2.793850 2.798142 2.592470
MONKEY    2.374532 3.715696 2.347531
DONKEY    0.000000 3.762978 4.007006
HIPPO     3.762978 0.000000 4.176374
> 
> 
> 
> cleanEx()
> nameEx("flexclustControl-class")
> ### * flexclustControl-class
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: flexclustControl-class
> ### Title: Classes "flexclustControl" and "cclustControl"
> ### Aliases: cclustControl flexclustControl flexclustControl-class
> ###   coerce,list,flexclustControl-method
> ###   coerce,NULL,flexclustControl-method cclustControl-class
> ###   coerce,list,cclustControl-method coerce,NULL,cclustControl-method
> ### Keywords: classes
> 
> ### ** Examples
> 
> ## have a look at the defaults
> new("flexclustControl")
An object of class "flexclustControl"
Slot "iter.max":
[1] 200

Slot "tolerance":
[1] 1e-06

Slot "verbose":
[1] 0

Slot "classify":
[1] "auto"

Slot "initcent":
[1] "randomcent"

Slot "gamma":
[1] 1

Slot "simann":
[1]  0.30  0.95 10.00

Slot "ntry":
[1] 5

Slot "min.size":
[1] 2

Slot "subsampling":
[1] 1

> 
> ## corce a list
> mycont = list(iter=500, tol=0.001, class="w")
> as(mycont, "flexclustControl")
An object of class "flexclustControl"
Slot "iter.max":
[1] 500

Slot "tolerance":
[1] 0.001

Slot "verbose":
[1] 0

Slot "classify":
[1] "weighted"

Slot "initcent":
[1] "randomcent"

Slot "gamma":
[1] 1

Slot "simann":
[1]  0.30  0.95 10.00

Slot "ntry":
[1] 5

Slot "min.size":
[1] 2

Slot "subsampling":
[1] 1

> 
> ## some additional slots
> as(mycont, "cclustControl")
An object of class "cclustControl"
Slot "pol.rate":
[1] 1 0

Slot "exp.rate":
[1] 1e-01 1e-04

Slot "ng.rate":
[1] 5e-01 5e-03 1e+01 1e-02

Slot "method":
[1] "polynomial"

Slot "iter.max":
[1] 500

Slot "tolerance":
[1] 0.001

Slot "verbose":
[1] 0

Slot "classify":
[1] "w"

Slot "initcent":
[1] "randomcent"

Slot "gamma":
[1] 1

Slot "simann":
[1]  0.30  0.95 10.00

Slot "ntry":
[1] 5

Slot "min.size":
[1] 2

Slot "subsampling":
[1] 1

> 
> ## default values for ng.rate
> new("cclustControl")@ng.rate
[1] 5e-01 5e-03 1e+01 1e-02
> 
> 
> 
> cleanEx()
> nameEx("flxColors")
> ### * flxColors
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: flxColors
> ### Title: Flexclust Color Palettes
> ### Aliases: flxColors
> ### Keywords: color
> 
> ### ** Examples
> 
> opar <- par(c("mfrow", "mar", "xaxt"))
> par(mfrow=c(2,2), mar=c(0,0,2,0), yaxt="n")
> 
> x <- rep(1, 8)
> 
> barplot(x, col = flxColors(color="full"), main="full")
> barplot(x, col = flxColors(color="dark"), main="dark")
> barplot(x, col = flxColors(color="medium"), main="medium")
> barplot(x, col = flxColors(color="light"), main="light")
> 
> par(opar)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("info")
> ### * info
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: info
> ### Title: Get Information on Fitted Flexclust Objects
> ### Aliases: info,flexclust,character-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> data("Nclus")
> plot(Nclus)
> 
> cl1 = cclust(Nclus, k=4)
> summary(cl1)
kcca object of family ‘kmeans’ 

call:
cclust(x = Nclus, k = 4)

cluster info:
  size  av_dist max_dist separation
1  200 1.155187 4.184644   2.846542
2  105 1.337802 2.892710   2.920576
3   98 1.475313 3.512398   3.424897
4  147 1.540631 4.460326   3.373556

convergence after 5 iterations
sum of within cluster distances: 742.5601 
> 
> ## these two are the same
> info(cl1)
[1] "size"       "av_dist"    "max_dist"   "separation" "distsum"   
> info(cl1, "help")
[1] "size"       "av_dist"    "max_dist"   "separation" "distsum"   
> 
> ## cluster sizes
> i1 = info(cl1, "size")
> i1
  1   2   3   4 
200 105  98 147 
> 
> ## average within cluster distances
> i2 = info(cl1, "av_dist")
> i2
       1        2        3        4 
1.155187 1.337802 1.475313 1.540631 
> 
> ## the sum of all within-cluster distances
> i3 = info(cl1, "distsum")
> i3
[1] 742.5601
> 
> ## sum(i1*i2) must of course be the same as i3
> stopifnot(all.equal(sum(i1*i2), i3))
> 
> 
> 
> ## This should return TRUE
> infoCheck(cl1, "size")
[1] TRUE
> ## and this FALSE
> infoCheck(cl1, "Homer Simpson")
[1] FALSE
> ## both combined
> i4 = infoCheck(cl1, c("size", "Homer Simpson"))
> i4
[1]  TRUE FALSE
> 
> stopifnot(all.equal(i4, c(TRUE, FALSE)))
> 
> 
> 
> cleanEx()
> nameEx("kcca")
> ### * kcca
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kcca
> ### Title: K-Centroids Cluster Analysis
> ### Aliases: kcca kccaFamily flexclust-class kcca-class kccasimple-class
> ###   kccaFamily-class show,kccasimple-method summary,kccasimple-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> data("Nclus")
> plot(Nclus)
> 
> ## try kmeans 
> cl1 = kcca(Nclus, k=4)
> cl1
kcca object of family ‘kmeans’ 

call:
kcca(x = Nclus, k = 4)

cluster sizes:

  1   2   3   4 
 99  64  88 299 

> 
> image(cl1)
> points(Nclus)
> 
> ## A barplot of the centroids 
> barplot(cl1)
> 
> 
> ## now use k-medians and kmeans++ initialization, cluster centroids
> ## should be similar...
> 
> cl2 = kcca(Nclus, k=4, family=kccaFamily("kmedians"),
+            control=list(initcent="kmeanspp"))
> cl2
kcca object of family ‘kmedians’ 

call:
kcca(x = Nclus, k = 4, family = kccaFamily("kmedians"), control = list(initcent = "kmeanspp"))

cluster sizes:

  1   2   3   4 
105  98 200 147 

> 
> ## ... but the boundaries of the partitions have a different shape
> image(cl2)
> points(Nclus)
> 
> 
> 
> cleanEx()
> nameEx("kcca2df")
> ### * kcca2df
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: kcca2df
> ### Title: Convert Cluster Result to Data Frame
> ### Aliases: kcca2df
> ### Keywords: cluster
> 
> ### ** Examples
> 
> c.iris <- cclust(iris[,-5], 3, save.data=TRUE)
> df.c.iris <- kcca2df(c.iris)
> summary(df.c.iris)
     value               variable   group  
 Min.   :0.100   Sepal.Length:150   1:152  
 1st Qu.:1.700   Sepal.Width :150   2:248  
 Median :3.200   Petal.Length:150   3:200  
 Mean   :3.465   Petal.Width :150          
 3rd Qu.:5.100                             
 Max.   :7.900                             
> densityplot(~value|variable+group, data=df.c.iris)
> 
> 
> 
> cleanEx()
> nameEx("priceFeature")
> ### * priceFeature
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: priceFeature
> ### Title: Artificial 2d Market Segment Data
> ### Aliases: priceFeature plot.priceFeature
> ### Keywords: datagen
> 
> ### ** Examples
> 
> plot(priceFeature(200, "2clust"))
> plot(priceFeature(200, "3clust"))
> plot(priceFeature(200, "5clust"))
> plot(priceFeature(200, "ell"))
> plot(priceFeature(200, "tri"))
> plot(priceFeature(200, "circ"))
> plot(priceFeature(200, "square"))
> plot(priceFeature(200, "largesmall"))
> 
> 
> 
> cleanEx()
> nameEx("projAxes")
> ### * projAxes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: projAxes
> ### Title: Add Arrows for Projected Axes to a Plot
> ### Aliases: projAxes projAxes projAxes-class plot,projAxes,missing-method
> ###   placeLabels placeLabels,projAxes-method
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data(milk)
> milk.pca <- prcomp(milk, scale=TRUE)
> 
> ## create a biplot step by step
> plot(predict(milk.pca), type="n")
> text(predict(milk.pca), rownames(milk), col="green", cex=0.8)
> projAxes(milk.pca)
> 
> ## the same, but arrows are blue, centered at origin and all arrows are
> ## plotted 
> plot(predict(milk.pca), type="n")
> text(predict(milk.pca), rownames(milk), col="green", cex=0.8)
> projAxes(milk.pca, col="blue", center=0, minradius=0)
> 
> ## use points instead of text, plot PC2 and PC3, manual radius
> ## specification, store result
> plot(predict(milk.pca)[,c(2,3)])
> arr <- projAxes(milk.pca, which=c(2,3), radius=1.2, plot=FALSE)
> plot(arr)
> 
> ## Not run: 
> ##D 
> ##D ## manually try to find new places for the labels: each arrow is marked
> ##D ## active in turn, use the left mouse button to find a better location
> ##D ## for the label. Use the right mouse button to go on to the next
> ##D ## variable.
> ##D 
> ##D arr1 <- placeLabels(arr)
> ##D 
> ##D ## now do the plot again:
> ##D plot(predict(milk.pca)[,c(2,3)])
> ##D plot(arr1)
> ## End(Not run)
> 
> 
> 
> 
> cleanEx()
> nameEx("propBarchart")
> ### * propBarchart
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: propBarchart
> ### Title: Barcharts and Boxplots for Columns of a Data Matrix Split by
> ###   Groups
> ### Aliases: propBarchart propBarchart-class show,propBarchart-method
> ###   summary,propBarchart-method groupBWplot
> ### Keywords: hplot
> 
> ### ** Examples
> 
>  ## create a binary matrix from the iris data plus a random noise column
>  x <- apply(iris[,-5], 2, function(z) z>median(z))
>  x <- cbind(x, Noise=sample(0:1, 150, replace=TRUE))
> 
>  ## There are significant differences in all 4 original variables, Noise
>  ## has most likely no significant difference (of course the difference
>  ## will be significant in alpha percent of all random samples).
>  p <- propBarchart(x, iris$Species)
>  p
>  summary(p)
             setosa versicolor virginica all p.value 
Sepal.Length 0      52         88        47  < 2e-16 
Sepal.Width  84     16         34        45  2.48e-11
Petal.Length 0      50         100       50  < 2e-16 
Petal.Width  0      44         100       48  < 2e-16 
Noise        54     42         52        49  .       
>  
>  x <- iris[,-5]
>  x <- cbind(x, Noise=rnorm(150, mean=3))
>  groupBWplot(x, iris$Species)
>  groupBWplot(x, iris$Species, shade=TRUE)
>  groupBWplot(x, iris$Species, shadefun="medianInside")
> 
> 
> 
> cleanEx()
> nameEx("qtclust")
> ### * qtclust
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: qtclust
> ### Title: Stochastic QT Clustering
> ### Aliases: qtclust
> ### Keywords: cluster
> 
> ### ** Examples
> 
> x <- matrix(10*runif(1000), ncol=2)
> 
> ## maximum distrance of point to cluster center is 3
> cl1 <- qtclust(x, radius=3)
> 
> ## maximum distrance of point to cluster center is 1
> ## -> more clusters, longer runtime
> cl2 <- qtclust(x, radius=1)
> 
> opar <- par(c("mfrow","mar"))
> par(mfrow=c(2,1), mar=c(2.1,2.1,1,1))
> plot(x, col=predict(cl1), xlab="", ylab="")
> plot(x, col=predict(cl2), xlab="", ylab="")
> par(opar)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("randIndex")
> ### * randIndex
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: randIndex
> ### Title: Compare Partitions
> ### Aliases: comPart comPart,flexclust,flexclust-method
> ###   comPart,numeric,numeric-method comPart,flexclust,numeric-method
> ###   comPart,numeric,flexclust-method randIndex
> ###   randIndex,table,missing-method randIndex,ANY,ANY-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> ## no class correlations: corrected Rand almost zero
> g1 <- sample(1:5, size=1000, replace=TRUE)
> g2 <- sample(1:5, size=1000, replace=TRUE)
> tab <- table(g1, g2)
> randIndex(tab)
         ARI 
0.0005188043 
> 
> ## uncorrected version will be large, because there are many points
> ## which are assigned to different clusters in both cases
> randIndex(tab, correct=FALSE)
       RI 
0.6802082 
> comPart(g1, g2)
         ARI           RI            J           FM 
0.0005188043 0.6802082082 0.1113435327 0.2003777385 
> 
> ## let pairs (g1=1,g2=1) and (g1=3,g2=3) agree better
> k <- sample(1:1000, size=200)
> g1[k] <- 1
> g2[k] <- 1
> k <- sample(1:1000, size=200)
> g1[k] <- 3
> g2[k] <- 3
> tab <- table(g1, g2)
> 
> ## the index should be larger than before
> randIndex(tab, correct=TRUE, original=TRUE)
      ARI        RI 
0.2486902 0.7222923 
> comPart(g1, g2)
      ARI        RI         J        FM 
0.2486902 0.7222923 0.2759384 0.4325265 
> 
> 
> 
> cleanEx()
> nameEx("randomTour")
> ### * randomTour
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: randomTour
> ### Title: Plot a Random Tour
> ### Aliases: randomTour randomTourMatrix randomTour,ANY-method
> ###   randomTour,flexclust-method randomTour,matrix-method
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
> if(interactive()){
+   par(ask=FALSE)
+   randomTour(iris[,1:4], axiscol=2:5)
+   randomTour(iris[,1:4], col=as.numeric(iris$Species), axiscol=4)
+ 
+   x <- matrix(runif(300), ncol=3)
+   x <- rbind(x, x+1, x+2)
+   cl <- cclust(x, k=3, save.data=TRUE)
+ 
+   randomTour(cl, center=0, axiscol="black")
+ 
+   ## now use predicted cluster membership for new data as colors
+   randomTour(cl, center=0, axiscol="black",
+              data=matrix(rnorm(3000, mean=1, sd=2), ncol=3))
+ }
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("shadow")
> ### * shadow
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: shadow
> ### Title: Cluster shadows and silhouettes
> ### Aliases: shadow shadow,kccasimple-method show,shadow-method
> ###   plot,shadow,ANY-method Silhouette Silhouette,kcca-method
> ###   show,Silhouette-method plot,Silhouette,ANY-method
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
> data(Nclus)
> set.seed(1)
> c5 <- cclust(Nclus, 5, save.data=TRUE)
> c5
kcca object of family ‘kmeans’ 

call:
cclust(x = Nclus, k = 5, save.data = TRUE)

cluster sizes:

  1   2   3   4   5 
198 105  52 147  48 

> plot(c5)
> 
> ## high shadow values indicate clusters with *bad* separation
> shadow(c5)
        1         2         3         4         5 
0.3832332 0.3894565 0.6327909 0.3979773 0.6106751 
> plot(shadow(c5))
> 
> ## high Silhouette values indicate clusters with *good* separation
> Silhouette(c5)
        1         2         3         4         5 
0.6537156 0.6333430 0.3344578 0.6336956 0.4170439 
> plot(Silhouette(c5))
> 
> 
> 
> cleanEx()
> nameEx("shadowStars")
> ### * shadowStars
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: shadowStars
> ### Title: Shadow Stars
> ### Aliases: shadowStars panelShadowViolin panelShadowBP
> ###   panelShadowSkeleton panelShadowStripes
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
> data(Nclus)
> set.seed(1)
> c5 <- cclust(Nclus, 5, save.data=TRUE)
> c5
kcca object of family ‘kmeans’ 

call:
cclust(x = Nclus, k = 5, save.data = TRUE)

cluster sizes:

  1   2   3   4   5 
198 105  52 147  48 

> plot(c5)
> 
> shadowStars(c5)
> shadowStars(c5, varwidth=TRUE)
> 
> shadowStars(c5, panel=panelShadowViolin)
> shadowStars(c5, panel=panelShadowBP)
> 
> ## always use varwidth=TRUE with panelShadowSkeleton, otherwise a few
> ## large shadow values can lead to misleading results:
> shadowStars(c5, panel=panelShadowSkeleton)
> shadowStars(c5, panel=panelShadowSkeleton, varwidth=TRUE)
> 
> 
> 
> cleanEx()
> nameEx("stepFlexclust")
> ### * stepFlexclust
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stepFlexclust
> ### Title: Run Flexclust Algorithms Repeatedly
> ### Aliases: stepFlexclust stepcclust stepFlexclust-class
> ###   show,stepFlexclust-method plot,stepFlexclust,missing-method getModel
> ###   getModel,stepFlexclust-method [[,stepFlexclust,ANY,missing-method
> ### Keywords: cluster
> 
> ### ** Examples
> 
> data("Nclus")
> plot(Nclus)
> 
> ## multicore off for CRAN checks
> cl1 = stepFlexclust(Nclus, k=2:7, FUN=cclust, multicore=FALSE)
2 : * * *
3 : * * *
4 : * * *
5 : * * *
6 : * * *
7 : * * *
> cl1
stepFlexclust object of family ‘kmeans’ 

call:
stepFlexclust(x = Nclus, k = 2:7, FUN = cclust, multicore = FALSE)

  iter converged   distsum
1   NA        NA 2267.8483
2    4      TRUE 1683.7331
3    7      TRUE 1171.7780
4    5      TRUE  742.5601
5    8      TRUE  656.8134
6   14      TRUE  620.9814
7   25      TRUE  575.6748
> 
> plot(cl1)
> 
> # two ways to do the same:
> getModel(cl1, 4)
kcca object of family ‘kmeans’ 

call:
stepFlexclust(x = Nclus, k = 5L, FUN = cclust, multicore = FALSE)

cluster sizes:

  1   2   3   4   5 
145 105  99 104  97 

> cl1[[4]]
kcca object of family ‘kmeans’ 

call:
stepFlexclust(x = Nclus, k = 5L, FUN = cclust, multicore = FALSE)

cluster sizes:

  1   2   3   4   5 
145 105  99 104  97 

> 
> opar=par("mfrow")
> par(mfrow=c(2,2))
> for(k in 3:6){
+   image(getModel(cl1, as.character(k)), data=Nclus)
+   title(main=paste(k, "clusters"))
+ }
> par(opar)
NULL
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("stripes")
> ### * stripes
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stripes
> ### Title: Stripes Plot
> ### Aliases: stripes
> ### Keywords: hplot
> 
> ### ** Examples
> 
> bw05 <- bundestag(2005)
> bavaria <- bundestag(2005, state="Bayern")
> 
> set.seed(1)
> c4 <- cclust(bw05, k=4, save.data=TRUE)
> plot(c4)
> 
> stripes(c4)
> stripes(c4, beside=TRUE)
> 
> stripes(c4, type="sec")
> stripes(c4, type="sec", beside=FALSE)
> stripes(c4, type="all")
> 
> stripes(c4, groups=bavaria)
> 
> ## ugly, but shows how colors of all parts can be changed
> library("grid")
> stripes(c4, type="all",
+         gp.bar=gpar(col="red", lwd=3, fill="white"),
+         gp.bar2=gpar(col="green", lwd=3, fill="black"))
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  19.396 0.168 19.578 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
